{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPaoKYMxbpBu"
   },
   "source": [
    "# **MAAS Audio Filtering**\n",
    "\n",
    "This notebook details the process of filtering wav audio files for usage in the MAAS project. The first four steps are an implementation of the process described by Salamon and GÃ³mez [2]. The rest is inspired by the research done by Wang [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFYWPZ4s64Oj"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import signal as sig\n",
    "from scipy.io import wavfile as wav\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjzqalmaMyZ2"
   },
   "outputs": [],
   "source": [
    "# Define Mauricio's Audio Analysis System function\n",
    "def MAAS_filter(data, sr = 44100, filename = None):\n",
    "  ## **Step 1.** Sinusoid Extraction\n",
    "  # 1.1. Equal Loudness Filtering\n",
    "  # Filter approximation by [1]\n",
    "\n",
    "  yule_b = np.array([0.05418656406430, -0.02911007808948, -0.00848709379851, -0.00851165645469,\n",
    "                     -0.00834990904936, 0.02245293253339, -0.02596338512915, 0.01624864962975,\n",
    "                     -0.00240879051584, 0.00674613682247, -0.00187763777362])\n",
    "  yule_a = np.array([1.0, -3.47845948550071, 6.36317777566148, -8.54751527471874, 9.47693607801280,\n",
    "                     -8.81498681370155, 6.85401540936998, -4.39470996079559, 2.19611684890774,\n",
    "                     -0.75104302451432, 0.13149317958808])\n",
    "  butter_b = np.array([0.98500175787242, -1.97000351574484, 0.98500175787242])\n",
    "  butter_a = np.array([1.0, -1.96977855582618, 0.97022847566350])\n",
    "\n",
    "  num = np.convolve(yule_b, butter_b)\n",
    "  den = np.convolve(yule_a, butter_a)\n",
    "\n",
    "  eq_data = sig.lfilter(num, den, data)\n",
    "  # 1.2. Spectral Transform\n",
    "  # Apply Short-Time Fourier Transform\n",
    "\n",
    "  # Constants as calculated by [2]\n",
    "  # Values specific to 44.1 kHz, should be scalable to other sample rates\n",
    "  M = 2048\n",
    "  N = 8192\n",
    "  H = 128\n",
    "\n",
    "  win = sig.windows.hann(M, False)\n",
    "  SFT = sig.ShortTimeFFT(win, hop=H, fs=sr, mfft=N, scale_to='magnitude')\n",
    "  Sx = SFT.stft(eq_data)\n",
    "  # Spectogram only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "  ax1.set(ylim=(0, 5000))\n",
    "\n",
    "  im1 = ax1.imshow(abs(Sx), origin='lower', aspect='auto',\n",
    "                   extent=SFT.extent(sr*np.size(data)), cmap='viridis')\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # 1.3. Frequency/Amplitude Correction\n",
    "  # Identify local maxima of each time frame\n",
    "\n",
    "  peaks = sig.argrelmax(abs(Sx), axis=0, order=2)\n",
    "  pcp = max(abs(Sx[peaks[0], peaks[1]])) / 20\n",
    "\n",
    "  peak_ids = np.zeros(0, dtype=int)\n",
    "  for i in range(peaks[0].size):\n",
    "    if abs(Sx[peaks[0][i], peaks[1][i]]) > pcp:\n",
    "      peak_ids = np.append(peak_ids, i)\n",
    "\n",
    "  peaks_f = peaks[0][peak_ids]\n",
    "  peaks_t = peaks[1][peak_ids]\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "  ax1.set(ylim=(0, 5000))\n",
    "\n",
    "  extents = SFT.extent(sr*data.size)\n",
    "  # x and y scale actually important. do not delete\n",
    "  x_scale = data.size/Sx.shape[1]\n",
    "  y_scale = sr/N\n",
    "\n",
    "  im1 = ax1.imshow(abs(Sx), origin='lower', aspect='auto',\n",
    "                   extent=extents, cmap='viridis')\n",
    "  ax1.plot(peaks_t * x_scale, peaks_f * y_scale, 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # Correct frequency and amplitude based on peaks' phase\n",
    "  # Done by computing instantaneous frequency (IF) and magnitude (Ai)\n",
    "  # Further clarification about this implementation by [4] and [5]\n",
    "\n",
    "  IF = np.zeros(peaks_f.size)\n",
    "  Ai = np.zeros(peaks_f.size)\n",
    "  koff = np.zeros(peaks_f.size)\n",
    "\n",
    "  for i in range(IF.size):\n",
    "    k_offset = np.angle(Sx[peaks_f[i], peaks_t[i]]) - (2*np.pi*H*peaks_f[i]/N)\n",
    "    if peaks_t[i] > 0: k_offset -= np.angle(Sx[peaks_f[i], peaks_t[i]-1])\n",
    "    k_offset = k_offset%(2*np.pi)\n",
    "    if k_offset > np.pi: k_offset -= 2*np.pi\n",
    "    Wh = np.sinc(k_offset) / (2*(1 - k_offset**2))\n",
    "    koff[i] = k_offset\n",
    "    k_offset *= N/(2*np.pi*H)\n",
    "\n",
    "    IF[i] = (peaks_f[i] + k_offset) * y_scale\n",
    "    Ai[i] = abs(Sx[peaks_f[i], peaks_t[i]]) / (2*Wh)\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "  ax1.set(ylim=(0, 5000))\n",
    "\n",
    "  im1 = ax1.imshow(abs(Sx), origin='lower', aspect='auto',\n",
    "                   extent=extents, cmap='viridis')\n",
    "  ax1.plot(peaks_t * x_scale, peaks_f * y_scale, 'r.')\n",
    "  ax1.plot(peaks_t * x_scale, IF, 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  ## **Step 2.** Salience Function Computation\n",
    "  # Calculate number of peaks and highest peak per frame\n",
    "\n",
    "  peaks_per_f = np.zeros(Sx.shape[1], dtype=int)\n",
    "  max_peak = np.zeros(peaks_per_f.size, dtype=int)\n",
    "\n",
    "  for i in range(peaks_t.size):\n",
    "    peaks_per_f[peaks_t[i]] += 1\n",
    "    if IF[i] > max_peak[peaks_t[i]]:\n",
    "      max_peak[peaks_t[i]] = i\n",
    "  # Useful function definitions\n",
    "\n",
    "  # Bin: Computes (discrete) bin number of given frequency\n",
    "  def Bin(fi):\n",
    "    return np.floor(120*np.log2(fi/55) + 1)\n",
    "\n",
    "  # Threshold: Whether or not a given peak is loud enough\n",
    "  # compared to highest peak in its frame\n",
    "  def Threshold(a, t, g):\n",
    "    if np.log10(abs(Ai[max_peak[t]] / a)) < g:\n",
    "      return 1\n",
    "    else: return 0\n",
    "\n",
    "  # Weight: Assigns (cos^2) weight to bin if the given peak is a\n",
    "  # multiple of the bin's center frequency (harmonic)\n",
    "  def Weight(a, b, h, fi):\n",
    "    d = abs(Bin(fi/h) - b)/10\n",
    "    if d <= 1:\n",
    "      return (a**(h-1)) * np.cos(np.pi*d/2)**2\n",
    "    else: return 0\n",
    "  # Constant values given by [2]\n",
    "  alpha = 0.8\n",
    "  beta = 1\n",
    "  gamma = 2\n",
    "  Nh = 20\n",
    "\n",
    "  # Useful peak indexing per frame\n",
    "  peaks_by_t = np.zeros((peaks_t.size, 2), dtype=int)\n",
    "  for i in range(peaks_t.size):\n",
    "    peaks_by_t[i] = [peaks_t[i], i]\n",
    "  peaks_by_t = peaks_by_t[np.argsort(peaks_by_t[:,0])]\n",
    "  # Computation of every bin's salience per frame\n",
    "\n",
    "  Sb = np.zeros((600, Sx.shape[1]))\n",
    "\n",
    "  index = 0\n",
    "  for l in range(Sb.shape[1]):\n",
    "    for b in range(Sb.shape[0]):\n",
    "      for n in range(peaks_per_f[l]):\n",
    "        idx = index + n\n",
    "        w = 0\n",
    "        ea = Threshold(Ai[peaks_by_t[idx,1]], l, gamma)\n",
    "        if ea == 0: continue\n",
    "        ab = abs(Ai[peaks_by_t[idx,1]])**beta\n",
    "        for h in range(Nh):\n",
    "          w += Weight(alpha, b+1, h+1, IF[peaks_by_t[idx,1]])\n",
    "        Sb[b, l] += w * ab\n",
    "    index += peaks_per_f[l]\n",
    "  # Figure only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  new_extents = (extents[0], extents[1], extents[2], 600.0)\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # Identify local maxima of each time frame\n",
    "\n",
    "  Speaks = sig.argrelmax(Sb, axis=0, order=5)\n",
    "  Speaks_arr = np.array([Speaks[0], Speaks[1]]).T\n",
    "  Speaks_arr = Speaks_arr[np.argsort(Speaks_arr[:,1])]\n",
    "  pcp2 = max(abs(Sb[Speaks_arr[:,0], Speaks_arr[:,1]])) / 10\n",
    "\n",
    "  Speak_ids = np.zeros(0, dtype=int)\n",
    "  for i in range(Speaks_arr.shape[0]):\n",
    "    if abs(Sb[Speaks_arr[i,0], Speaks_arr[i,1]]) > pcp2:\n",
    "      Speak_ids = np.append(Speak_ids, i)\n",
    "\n",
    "  Speaks_b = Speaks_arr[Speak_ids, 0]\n",
    "  Speaks_t = Speaks_arr[Speak_ids, 1]\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "  ax1.plot(Speaks_t * x_scale, Speaks_b, 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  ## **Step 3.** Peak Streaming\n",
    "  # Calculate highest salience peaks per frame\n",
    "  # and filter low salience peaks\n",
    "\n",
    "  peak_Sb = Sb[Speaks_b, Speaks_t]\n",
    "  max_Speak = np.zeros(Sb.shape[1], dtype=int)\n",
    "  S_minus = np.zeros(0, dtype=int)\n",
    "\n",
    "  for i in range(peak_Sb.size):\n",
    "    if peak_Sb[i] > peak_Sb[max_Speak[Speaks_t[i]]]:\n",
    "      max_Speak[Speaks_t[i]] = i\n",
    "\n",
    "  for i in range(peak_Sb.size):\n",
    "    max_id = max_Speak[Speaks_t[i]]\n",
    "    if peak_Sb[i] < (peak_Sb[max_id] * 0.9):\n",
    "      S_minus = np.append(S_minus, i)\n",
    "  # Filter remaining peaks based on general frame salience\n",
    "\n",
    "  boolarr = np.ones(peak_Sb.size, dtype=bool)\n",
    "  for i in S_minus: boolarr[i] = False\n",
    "\n",
    "  N = peak_Sb.size - S_minus.size\n",
    "  s_mean = np.average(peak_Sb[boolarr])\n",
    "  s_dev = np.std(peak_Sb[boolarr])\n",
    "  min_S = s_mean - 0.9*s_dev\n",
    "\n",
    "  for a in range(peak_Sb.size):\n",
    "    if boolarr[a] == 1 and peak_Sb[a] < min_S:\n",
    "      S_minus = np.append(S_minus, a)\n",
    "      boolarr[a] = 0\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "  ax1.plot(Speaks_t[boolarr] * x_scale, Speaks_b[boolarr], 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # Actual contour creation\n",
    "  # Travel through the remaining ordered peaks and group them based on\n",
    "  # time and pitch continuity\n",
    "  # Might use some filtered peaks to maintain the continuities\n",
    "\n",
    "  S_plus = np.array(np.where(boolarr == 1)).flatten()\n",
    "  contours = []\n",
    "  first_f = min(Speaks_t)\n",
    "  last_f = max(Speaks_t)\n",
    "\n",
    "  while S_plus.size:\n",
    "    wpeak_Sb = np.copy(peak_Sb[S_plus])\n",
    "    it = np.argmax(wpeak_Sb)\n",
    "    it2 = 0\n",
    "    for i in range(S_minus.size):\n",
    "      if Speaks_t[S_minus[i]] == Speaks_t[it]:\n",
    "        it2 = i\n",
    "        break\n",
    "\n",
    "    c_contour = np.zeros(1, dtype=int)\n",
    "    c_delete = np.zeros(1, dtype=int)\n",
    "    c_delete2 = np.zeros(1, dtype=int)\n",
    "    c_contour[0] = S_plus[it]\n",
    "    c_delete[0] = it\n",
    "\n",
    "    # Forward\n",
    "    last_p = S_plus[it]\n",
    "    last = it\n",
    "    os = 1\n",
    "    last2 = it2\n",
    "    os2 = 1\n",
    "    gap = 1\n",
    "\n",
    "    while gap < 35 and (Speaks_t[last_p] + gap) <= last_f:\n",
    "      if (it+os) < S_plus.size and Speaks_t[S_plus[it+os]] == Speaks_t[last_p]:\n",
    "        os += 1\n",
    "      elif (it+os) < S_plus.size and Speaks_t[S_plus[it+os]] == Speaks_t[last_p] + gap:\n",
    "        if abs(Speaks_b[S_plus[it+os]] - Speaks_b[last_p]) < 9:\n",
    "          last = it + os\n",
    "          last_p = S_plus[last]\n",
    "          c_contour = np.append(c_contour, last_p)\n",
    "          c_delete = np.append(c_delete, last)\n",
    "          gap = 1\n",
    "        os += 1\n",
    "      else:\n",
    "        if (it2+os2) < S_minus.size and Speaks_t[S_minus[it2+os2]] == Speaks_t[last_p]:\n",
    "          os2 += 1\n",
    "        elif (it2+os2) < S_minus.size and Speaks_t[S_minus[it2+os2]] == Speaks_t[last_p] + gap:\n",
    "          if abs(Speaks_b[S_minus[it2+os2]] - Speaks_b[last_p]) < 9:\n",
    "            last2 = it2 + os2\n",
    "            last_p = S_minus[last2]\n",
    "            c_contour = np.append(c_contour, last_p)\n",
    "            c_delete2 = np.append(c_delete2, last2)\n",
    "            gap = 1\n",
    "          os2 += 1\n",
    "        else: gap += 1\n",
    "\n",
    "    # Backward\n",
    "    c_contour = np.flip(c_contour)\n",
    "    last_p = S_plus[it]\n",
    "    last = it\n",
    "    os = 1\n",
    "    last2 = it2\n",
    "    os2 = 1\n",
    "    gap = 1\n",
    "\n",
    "    while gap < 35 and (Speaks_t[last_p] - gap) >= first_f:\n",
    "      if (it-os) >= 0 and Speaks_t[S_plus[it-os]] == Speaks_t[last_p]:\n",
    "        os += 1\n",
    "      elif (it-os) >= 0 and Speaks_t[S_plus[it-os]] == Speaks_t[last_p] - gap:\n",
    "        if abs(Speaks_b[S_plus[it-os]] - Speaks_b[last_p]) < 9:\n",
    "          last = it - os\n",
    "          last_p = S_plus[last]\n",
    "          c_contour = np.append(c_contour, last_p)\n",
    "          c_delete = np.append(c_delete, last)\n",
    "          gap = 1\n",
    "        os += 1\n",
    "      else:\n",
    "        if (it2-os2) >= 0 and Speaks_t[S_minus[it2-os2]] == Speaks_t[last_p]:\n",
    "          os2 += 1\n",
    "        elif (it2-os2) >= 0 and Speaks_t[S_minus[it2-os2]] == Speaks_t[last_p] - gap:\n",
    "          if abs(Speaks_b[S_minus[it2-os2]] - Speaks_b[last_p]) < 9:\n",
    "            last2 = it2 - os2\n",
    "            last_p = S_minus[last2]\n",
    "            c_contour = np.append(c_contour, last_p)\n",
    "            c_delete2 = np.append(c_delete2, last2)\n",
    "            gap = 1\n",
    "          os2 += 1\n",
    "        else: gap += 1\n",
    "\n",
    "    c_contour = np.flip(c_contour)\n",
    "    contours += [c_contour]\n",
    "\n",
    "    S_plus = np.delete(S_plus, c_delete)\n",
    "    S_minus = np.delete(S_minus, c_delete2)\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  #im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   #extent=new_extents, cmap='viridis')\n",
    "  for arr in contours:\n",
    "    ax1.plot(Speaks_t[arr] * x_scale, Speaks_b[arr], '.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  ## **Step 4.** Melody Selection\n",
    "  # Calculate certain attributes for each contour\n",
    "\n",
    "  p_mean = np.array([np.mean(Speaks_b[arr]) for arr in contours])\n",
    "  p_std = np.array([np.std(Speaks_b[arr]) for arr in contours])\n",
    "  s_mean = np.array([np.mean(peak_Sb[arr]) for arr in contours])\n",
    "  s_total = np.array([np.sum(peak_Sb[arr]) for arr in contours])\n",
    "  s_std = np.array([np.std(peak_Sb[arr]) for arr in contours])\n",
    "  # 4.1. Voicing Detection\n",
    "  # Give contours with considerable pitch deviation \"immunity\"\n",
    "  # for the rest of this step\n",
    "\n",
    "  vib = np.zeros(0, dtype=int)\n",
    "  for c in range(s_std.size):\n",
    "    if p_std[c] >= 4: vib = np.append(vib, c)\n",
    "\n",
    "  # Filter contours with low salience\n",
    "\n",
    "  s_meanmean = np.mean(s_mean)\n",
    "  s_meanstd = np.std(s_mean)\n",
    "  v = 0.4\n",
    "  del2 = np.zeros(0, dtype=int)\n",
    "\n",
    "  for c in range(s_mean.size):\n",
    "    if c not in vib and s_mean[c] < (s_meanmean - v*s_meanstd):\n",
    "      del2 = np.append(del2, c)\n",
    "  del2 = np.flip(del2)\n",
    "  for d in range(del2.size):\n",
    "    del contours[del2[d]]\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  for arr in contours:\n",
    "    ax1.plot(Speaks_t[arr] * x_scale, Speaks_b[arr], '.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # 4.2. Octave Errors and Pitch Outliers\n",
    "  # Function definitions\n",
    "\n",
    "  # Derive melody pitch mean from given contours\n",
    "  def CreatePt(cont, pm, sm):\n",
    "    Pt = np.zeros(Sb.shape[1])\n",
    "    Pt_d = np.zeros(Sb.shape[1])\n",
    "\n",
    "    for i in range(len(cont)):\n",
    "      for j in range(cont[i].size):\n",
    "        k = Speaks_t[cont[i][j]]\n",
    "        Pt[k] += Speaks_b[cont[i][j]]*peak_Sb[cont[i][j]]\n",
    "        Pt_d[k] += peak_Sb[cont[i][j]]\n",
    "    for i in range(Pt.size):\n",
    "      if Pt_d[i] != 0: Pt[i] /= Pt_d[i]\n",
    "\n",
    "    Pt_ = np.zeros(Pt.size)\n",
    "    for i in range(Pt_.size):\n",
    "      n = 0\n",
    "      for m in range(1, 860):\n",
    "        if (i - m) < 0: break\n",
    "        if Pt[i-m] == 0: continue\n",
    "        Pt_[i] += Pt[i-m]\n",
    "        n += 1\n",
    "      for m in range(1, 860):\n",
    "        if (i + m) >= Pt.size: break\n",
    "        if Pt[i+m] == 0: continue\n",
    "        Pt_[i] += Pt[i+m]\n",
    "        n += 1\n",
    "      if n != 0: Pt_[i] /= n\n",
    "\n",
    "    return Pt_\n",
    "\n",
    "  # Find contour overlap sections\n",
    "  def Overlaps(cont):\n",
    "    overlaps = []\n",
    "    timer = []\n",
    "    for _ in range(Sb.shape[1]): timer += [np.zeros(0, dtype=int)]\n",
    "\n",
    "    for i in range(len(cont)):\n",
    "      for j in range(Speaks_t[cont[i][0]], Speaks_t[cont[i][-1]]+1):\n",
    "        for a in range(timer[j].size):\n",
    "          i2 = timer[j][a]\n",
    "          done = 0\n",
    "          for k in range(len(overlaps)):\n",
    "            if overlaps[k][0] == i and overlaps[k][1] == i2:\n",
    "              done = 1\n",
    "              break\n",
    "          if done == 1: continue\n",
    "\n",
    "          last = min([Speaks_t[cont[i][-1]], Speaks_t[cont[i2][-1]]])\n",
    "          overlaps += [np.array([i, i2, j, last])]\n",
    "\n",
    "          new_x = len(overlaps) - 1\n",
    "          for k in range(len(overlaps)-1):\n",
    "            if (overlaps[k][0] == i or overlaps[k][1] == i or\n",
    "                overlaps[k][0] == i2 or overlaps[k][1] == i2):\n",
    "              if ((overlaps[k][3] - overlaps[k][2]) <\n",
    "                  (overlaps[new_x][3] - overlaps[new_x][2])) and k > new_x:\n",
    "                overlaps[k], overlaps[new_x] = overlaps[new_x], overlaps[k]\n",
    "                new_x = k\n",
    "        timer[j] = np.append(timer[j], i)\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "  # Detect pairs of octave duplicates and pick closest to Pt\n",
    "  def PickOctave(over, Pt):\n",
    "    cont0 = contours[over[0]]\n",
    "    cont1 = contours[over[1]]\n",
    "    dif = np.zeros(0)\n",
    "    pt0 = np.zeros(0)\n",
    "    pt1 = np.zeros(0)\n",
    "    i0 = 0\n",
    "    i1 = 0\n",
    "\n",
    "    while Speaks_t[cont0[i0]] != over[2]:\n",
    "      if (i0+1) >= (cont0.size): break\n",
    "      else: i0 += 1\n",
    "    while Speaks_t[cont1[i1]] != over[2]:\n",
    "      if (i1+1) >= (cont1.size): break\n",
    "      else: i1 += 1\n",
    "    for t in range(over[2], over[3]+1):\n",
    "      while Speaks_t[cont0[i0]] < t:\n",
    "        if (i0+1) >= (cont0.size): break\n",
    "        else: i0 += 1\n",
    "      if Speaks_t[cont0[i0]] > t: continue\n",
    "      while Speaks_t[cont1[i1]] < t:\n",
    "        if (i1+1) >= (cont1.size): break\n",
    "        else: i1 += 1\n",
    "      if Speaks_t[cont1[i1]] > t: continue\n",
    "\n",
    "      b0 = Speaks_b[cont0[i0]]\n",
    "      b1 = Speaks_b[cont1[i1]]\n",
    "      dif = np.append(dif, abs(b0 - b1))\n",
    "      pt0 = np.append(pt0, abs(Pt[t] - b0))\n",
    "      pt1 = np.append(pt1, abs(Pt[t] - b1))\n",
    "\n",
    "    if np.mean(dif) >= 115 and np.mean(dif) <= 125:\n",
    "      if np.mean(pt0) == np.mean(pt1): return 0\n",
    "      elif np.mean(pt0) < np.mean(pt1): return 1\n",
    "      else: return 2\n",
    "    else: return 0\n",
    "  # Filter out octave duplicates and pitch outliers\n",
    "  # Repeat process three times with updated melody pitch means\n",
    "\n",
    "  Pt = CreatePt(contours, p_mean, s_mean)\n",
    "  overlaps = Overlaps(contours)\n",
    "\n",
    "  for _ in range(3):\n",
    "    rest = range(len(contours))\n",
    "\n",
    "    rest2 = []\n",
    "    for over in overlaps:\n",
    "      if over[0] in rest2 or over[1] in rest2: continue\n",
    "      result = PickOctave(over, Pt)\n",
    "      if result == 1: octave = over[1]\n",
    "      elif result == 2: octave = over[0]\n",
    "      if result != 0:\n",
    "        rest2 += [octave]\n",
    "    rest = [r for r in rest if r not in rest2]\n",
    "    crest = []\n",
    "    for c in range(len(rest)): crest += [contours[rest[c]]]\n",
    "    Pt = CreatePt(crest, p_mean[rest], s_mean[rest])\n",
    "\n",
    "    rest2 = []\n",
    "    for i in range(len(rest)):\n",
    "      cont = crest[i]\n",
    "      ptdif = np.zeros(0)\n",
    "      for j in range(cont.size):\n",
    "        t = Speaks_t[cont[j]]\n",
    "        ptdif = np.append(ptdif, abs(Speaks_b[cont[j]] - Pt[t]))\n",
    "      if np.mean(ptdif) > 120:\n",
    "        rest2 += [rest[i]]\n",
    "    rest = [r for r in rest if r not in rest2]\n",
    "    crest = []\n",
    "    for c in range(len(rest)): crest += [contours[rest[c]]]\n",
    "    Pt = CreatePt(crest, p_mean[rest], s_mean[rest])\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  for arr in crest:\n",
    "    ax1.plot(Speaks_t[arr], Speaks_b[arr], 'k.')\n",
    "  ax1.plot(np.arange(Pt.size), Pt, 'r--')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # 4.3. Final Melody Selection\n",
    "\n",
    "  contours = crest\n",
    "  s_total2 = s_total[rest]\n",
    "  not_final = []\n",
    "\n",
    "  overlaps = Overlaps(contours)\n",
    "  for i in range(len(overlaps)):\n",
    "    over = overlaps[i]\n",
    "    if s_total2[over[0]] < s_total2[over[1]]: not_final += [over[0]]\n",
    "    else: not_final += [over[1]]\n",
    "\n",
    "  final = range(len(contours))\n",
    "  final = [f for f in final if f not in not_final]\n",
    "  final_contours = []\n",
    "  for f in range(len(final)): final_contours += [contours[final[f]]]\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "  for arr in final_contours:\n",
    "    ax1.plot(Speaks_t[arr] * x_scale, Speaks_b[arr], 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  for i in range(len(final_contours)):\n",
    "    for j in range(i+1, len(final_contours)):\n",
    "      if final_contours[i][0] > final_contours[j][0]:\n",
    "        final_contours[i], final_contours[j] = final_contours[j], final_contours[i]\n",
    "\n",
    "  final_t = np.zeros(0, dtype=int)\n",
    "  final_b = np.zeros(0, dtype=int)\n",
    "  for f in final_contours:\n",
    "    final_t = np.append(final_t, Speaks_t[f])\n",
    "    final_b = np.append(final_b, Speaks_b[f])\n",
    "\n",
    "  if (filename is not None):\n",
    "    with open(filename, \"w\") as txt:\n",
    "      txt.write(\"Time,Pitch\\n\")\n",
    "      for i in range(final_t.size):\n",
    "        txt.write(str(final_t[i]) + \",\" + str(final_b[i]) + \"\\n\")\n",
    "  return [final_t, final_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0Im9iYA65Io"
   },
   "source": [
    "## References\n",
    "\n",
    "[1] https://replaygain.hydrogenaud.io/equal_loudness.html \\\\\n",
    "[2] https://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamongomezmelodytaslp2012.pdf \\\\\n",
    "[3] https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf \\\\\n",
    "[4] https://dafx.de/paper-archive/2006/papers/p_247.pdf \\\\\n",
    "[5] https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00038847/ilm1-2017000136.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
