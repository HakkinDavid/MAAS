{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MAAS Filter Function**\n",
    "\n",
    "This notebook details the process of filtering wav audio files for usage in the MAAS project. The first four steps are an implementation of the process described by Salamon and GÃ³mez [2]. The rest is inspired by the research done by Wang [3].\n",
    "\n",
    "DISCLAIMER: English was purposely used to write comments and cells as it suits our ideas better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFYWPZ4s64Oj"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import signal as sig\n",
    "from scipy.io import wavfile as wav\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjzqalmaMyZ2"
   },
   "outputs": [],
   "source": [
    "# Define Mauricio's Audio Analysis System function\n",
    "def MAAS_filter(data, sr = 44100, filename = None):\n",
    "  ## **Step 1.** Sinusoid Extraction\n",
    "  # 1.1. Equal Loudness Filtering\n",
    "  # Filter approximation by [1]\n",
    "\n",
    "  yule_b = np.array([0.05418656406430, -0.02911007808948, -0.00848709379851, -0.00851165645469,\n",
    "                     -0.00834990904936, 0.02245293253339, -0.02596338512915, 0.01624864962975,\n",
    "                     -0.00240879051584, 0.00674613682247, -0.00187763777362])\n",
    "  yule_a = np.array([1.0, -3.47845948550071, 6.36317777566148, -8.54751527471874, 9.47693607801280,\n",
    "                     -8.81498681370155, 6.85401540936998, -4.39470996079559, 2.19611684890774,\n",
    "                     -0.75104302451432, 0.13149317958808])\n",
    "  butter_b = np.array([0.98500175787242, -1.97000351574484, 0.98500175787242])\n",
    "  butter_a = np.array([1.0, -1.96977855582618, 0.97022847566350])\n",
    "\n",
    "  num = np.convolve(yule_b, butter_b)\n",
    "  den = np.convolve(yule_a, butter_a)\n",
    "\n",
    "  eq_data = sig.lfilter(num, den, data)\n",
    "  # 1.2. Spectral Transform\n",
    "  # Apply Short-Time Fourier Transform\n",
    "\n",
    "  # Constants as calculated by [2]\n",
    "  # Values specific to 44.1 kHz, should be scalable to other sample rates\n",
    "  M = 2048\n",
    "  N = 8192\n",
    "  H = 128\n",
    "\n",
    "  win = sig.windows.hann(M, False)\n",
    "  SFT = sig.ShortTimeFFT(win, hop=H, fs=sr, mfft=N, scale_to='magnitude')\n",
    "  Sx = SFT.stft(eq_data)\n",
    "  # Spectogram only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "  ax1.set(ylim=(0, 5000))\n",
    "\n",
    "  im1 = ax1.imshow(abs(Sx), origin='lower', aspect='auto',\n",
    "                   extent=SFT.extent(sr*np.size(data)), cmap='viridis')\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # 1.3. Frequency/Amplitude Correction\n",
    "  # Identify local maxima of each time frame\n",
    "\n",
    "  peaks = sig.argrelmax(abs(Sx), axis=0, order=2)\n",
    "  pcp = max(abs(Sx[peaks[0], peaks[1]])) / 20\n",
    "  peak_ids = abs(Sx[peaks[0], peaks[1]]) > pcp\n",
    "  peaks_f = peaks[0][peak_ids]\n",
    "  peaks_t = peaks[1][peak_ids]\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "  ax1.set(ylim=(0, 5000))\n",
    "\n",
    "  extents = SFT.extent(sr*data.size)\n",
    "  # x and y scale actually important. do not delete\n",
    "  x_scale = data.size/Sx.shape[1]\n",
    "  y_scale = sr/N\n",
    "\n",
    "  im1 = ax1.imshow(abs(Sx), origin='lower', aspect='auto',\n",
    "                   extent=extents, cmap='viridis')\n",
    "  ax1.plot(peaks_t * x_scale, peaks_f * y_scale, 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # Correct frequency and amplitude based on peaks' phase\n",
    "  # Done by computing instantaneous frequency (IF) and magnitude (Ai)\n",
    "  # Further clarification about this implementation by [4] and [5]\n",
    "\n",
    "  y_scale = sr/N\n",
    "  k_offset = np.angle(Sx[peaks_f, peaks_t]) - (2*np.pi*H*peaks_f/N)\n",
    "  mask = peaks_t > 0\n",
    "  k_offset[mask] -= np.angle(Sx[peaks_f[mask], peaks_t[mask]-1])\n",
    "  k_offset = k_offset%(2*np.pi)\n",
    "  mask = k_offset > np.pi\n",
    "  k_offset[mask] -= 2*np.pi\n",
    "  Wh = np.sinc(k_offset) / (2*(1 - k_offset**2))\n",
    "  k_offset *= N/(2*np.pi*H)\n",
    "\n",
    "  IF = (peaks_f + k_offset) * y_scale\n",
    "  Ai = abs(Sx[peaks_f, peaks_t]) / (2*Wh)\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "  ax1.set(ylim=(0, 5000))\n",
    "\n",
    "  im1 = ax1.imshow(abs(Sx), origin='lower', aspect='auto',\n",
    "                   extent=extents, cmap='viridis')\n",
    "  ax1.plot(peaks_t * x_scale, peaks_f * y_scale, 'r.')\n",
    "  ax1.plot(peaks_t * x_scale, IF, 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  ## **Step 2.** Salience Function Computation\n",
    "  # Constant values given by [2]\n",
    "  alpha = 0.8\n",
    "  beta = 1\n",
    "  gamma = 2\n",
    "  Nh = 20\n",
    "\n",
    "  # Useful peak indexing per frame\n",
    "  peaks_by_t = np.asarray(tuple(zip(peaks_t, range(peaks_t.size))))\n",
    "  peaks_by_t = peaks_by_t[np.argsort(peaks_by_t[:,0])]\n",
    "\n",
    "  # Calculate number of peaks and highest peak per frame\n",
    "  peaks_per_f = np.zeros(Sx.shape[1], dtype=int)\n",
    "  max_peak = np.zeros(peaks_per_f.size, dtype=int)\n",
    "\n",
    "  for i in range(peaks_t.size):\n",
    "    peaks_per_f[peaks_t[i]] += 1\n",
    "    if IF[i] > max_peak[peaks_t[i]]:\n",
    "      max_peak[peaks_t[i]] = i\n",
    "  # Function definitions\n",
    "\n",
    "  # Bin: Computes (discrete) bin number of given frequency\n",
    "  def Bin(fi):\n",
    "    return np.floor(120*np.log2(fi/55) + 1)\n",
    "\n",
    "  # Threshold: Whether or not a given peak is loud enough\n",
    "  # compared to highest peak in its frame\n",
    "  def Threshold(a, t, g):\n",
    "    tr = np.log10(abs(Ai[max_peak[t]] / a))\n",
    "    ea = np.where(tr < g, 1, 0)\n",
    "    return ea\n",
    "\n",
    "  # Weight: Assigns (cos^2) weight to bin if the given peak is a\n",
    "  # multiple of the bin's center frequency (harmonic)\n",
    "  def Weight(a, b, h, fi):\n",
    "    nh = np.arange(h)+1\n",
    "    d = abs(Bin(np.outer(fi, (1 / nh))) - b)/10\n",
    "    w = (a**(nh-1)) * np.cos(np.pi*d/2)**2\n",
    "    w[(d > 1)] = 0\n",
    "    return np.sum(w, axis=1)\n",
    "  # Computation of every bin's salience per frame\n",
    "\n",
    "  Sb = np.zeros((600, Sx.shape[1]))\n",
    "\n",
    "  index = 0\n",
    "  for l in range(Sb.shape[1]):\n",
    "    idx = slice(index, index + peaks_per_f[l])\n",
    "    ea = Threshold(Ai[peaks_by_t[idx,1]], l, gamma)\n",
    "    ab = abs(Ai[peaks_by_t[idx,1]])**beta\n",
    "    for b in range(Sb.shape[0]):\n",
    "      w = Weight(alpha, b+1, Nh, IF[peaks_by_t[idx,1]])\n",
    "      Sb[b, l] = np.sum(w * ab)\n",
    "    index += peaks_per_f[l]\n",
    "  # Figure only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  new_extents = (extents[0], extents[1], extents[2], 600.0)\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # Identify local maxima of each time frame\n",
    "\n",
    "  Speaks = sig.argrelmax(Sb, axis=0, order=5)\n",
    "  Speaks_arr = np.array([Speaks[0], Speaks[1]]).T\n",
    "  Speaks_arr = Speaks_arr[np.argsort(Speaks_arr[:,1])]\n",
    "\n",
    "  pcp2 = max(abs(Sb[Speaks_arr[:,0], Speaks_arr[:,1]])) / 10\n",
    "  Speak_ids = abs(Sb[Speaks_arr[:,0], Speaks_arr[:,1]]) > pcp2\n",
    "  Speaks_b = Speaks_arr[Speak_ids, 0].flatten()\n",
    "  Speaks_t = Speaks_arr[Speak_ids, 1].flatten()\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "  ax1.plot(Speaks_t * x_scale, Speaks_b, 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  ## **Step 3.** Peak Streaming\n",
    "  # Calculate highest salience peaks per frame\n",
    "  # and filter low salience peaks\n",
    "\n",
    "  peak_Sb = Sb[Speaks_b, Speaks_t]\n",
    "  max_Speak = np.zeros(Sb.shape[1], dtype=int)\n",
    "\n",
    "  for i in range(peak_Sb.size):\n",
    "    if peak_Sb[i] > peak_Sb[max_Speak[Speaks_t[i]]]:\n",
    "      max_Speak[Speaks_t[i]] = i\n",
    "\n",
    "  max_id = max_Speak[Speaks_t]\n",
    "  mask = peak_Sb < peak_Sb[max_id] * 0.9\n",
    "  S_minus = np.arange(peak_Sb.size)[mask]\n",
    "  # Filter remaining peaks based on general frame salience\n",
    "\n",
    "  boolarr = np.ones(peak_Sb.size, dtype=bool)\n",
    "  boolarr[S_minus] = False\n",
    "\n",
    "  N = peak_Sb.size - S_minus.size\n",
    "  s_mean = np.average(peak_Sb[boolarr])\n",
    "  s_dev = np.std(peak_Sb[boolarr])\n",
    "  min_S = s_mean - 0.9*s_dev\n",
    "\n",
    "  mask = (boolarr == 1) & (peak_Sb < min_S)\n",
    "  S_minus = np.append(S_minus, np.arange(peak_Sb.size)[mask])\n",
    "  boolarr[mask] = 0\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "  ax1.plot(Speaks_t[boolarr] * x_scale, Speaks_b[boolarr], 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # Actual contour creation\n",
    "  # Travel through the remaining ordered peaks and group them based on\n",
    "  # time and pitch continuity\n",
    "  # Might use some filtered peaks to maintain the continuities\n",
    "\n",
    "  S_plus = np.array(np.where(boolarr == 1)).flatten()\n",
    "  contours = np.zeros(0, dtype=int)\n",
    "  contour_ids = np.array([], dtype=slice)\n",
    "  first_f = min(Speaks_t)\n",
    "  last_f = max(Speaks_t)\n",
    "\n",
    "  while S_plus.size:\n",
    "    wpeak_Sb = np.copy(peak_Sb[S_plus])\n",
    "    it = np.argmax(wpeak_Sb)\n",
    "    it2 = 0\n",
    "    mask = Speaks_t[S_minus] == Speaks_t[it]\n",
    "    if mask.any(): it2 = np.arange(S_minus.size)[mask][0]\n",
    "\n",
    "    c_contour = np.zeros(1, dtype=int)\n",
    "    c_delete = np.zeros(1, dtype=int)\n",
    "    c_delete2 = np.zeros(1, dtype=int)\n",
    "    c_contour[0] = S_plus[it]\n",
    "    c_delete[0] = it\n",
    "\n",
    "    # Forward\n",
    "    last_p = S_plus[it]\n",
    "    last = it\n",
    "    os = 1\n",
    "    last2 = it2\n",
    "    os2 = 1\n",
    "    gap = 1\n",
    "\n",
    "    while gap < 35 and (Speaks_t[last_p] + gap) <= last_f:\n",
    "      if (it+os) < S_plus.size and Speaks_t[S_plus[it+os]] == Speaks_t[last_p]:\n",
    "        os += 1\n",
    "      elif (it+os) < S_plus.size and Speaks_t[S_plus[it+os]] == Speaks_t[last_p] + gap:\n",
    "        if abs(Speaks_b[S_plus[it+os]] - Speaks_b[last_p]) < 9:\n",
    "          last = it + os\n",
    "          last_p = S_plus[last]\n",
    "          c_contour = np.append(c_contour, last_p)\n",
    "          c_delete = np.append(c_delete, last)\n",
    "          gap = 1\n",
    "        os += 1\n",
    "      else:\n",
    "        if (it2+os2) < S_minus.size and Speaks_t[S_minus[it2+os2]] == Speaks_t[last_p]:\n",
    "          os2 += 1\n",
    "        elif (it2+os2) < S_minus.size and Speaks_t[S_minus[it2+os2]] == Speaks_t[last_p] + gap:\n",
    "          if abs(Speaks_b[S_minus[it2+os2]] - Speaks_b[last_p]) < 9:\n",
    "            last2 = it2 + os2\n",
    "            last_p = S_minus[last2]\n",
    "            c_contour = np.append(c_contour, last_p)\n",
    "            c_delete2 = np.append(c_delete2, last2)\n",
    "            gap = 1\n",
    "          os2 += 1\n",
    "        else: gap += 1\n",
    "\n",
    "    # Backward\n",
    "    c_contour = np.flip(c_contour)\n",
    "    last_p = S_plus[it]\n",
    "    last = it\n",
    "    os = 1\n",
    "    last2 = it2\n",
    "    os2 = 1\n",
    "    gap = 1\n",
    "\n",
    "    while gap < 35 and (Speaks_t[last_p] - gap) >= first_f:\n",
    "      if (it-os) >= 0 and Speaks_t[S_plus[it-os]] == Speaks_t[last_p]:\n",
    "        os += 1\n",
    "      elif (it-os) >= 0 and Speaks_t[S_plus[it-os]] == Speaks_t[last_p] - gap:\n",
    "        if abs(Speaks_b[S_plus[it-os]] - Speaks_b[last_p]) < 9:\n",
    "          last = it - os\n",
    "          last_p = S_plus[last]\n",
    "          c_contour = np.append(c_contour, last_p)\n",
    "          c_delete = np.append(c_delete, last)\n",
    "          gap = 1\n",
    "        os += 1\n",
    "      else:\n",
    "        if (it2-os2) >= 0 and Speaks_t[S_minus[it2-os2]] == Speaks_t[last_p]:\n",
    "          os2 += 1\n",
    "        elif (it2-os2) >= 0 and Speaks_t[S_minus[it2-os2]] == Speaks_t[last_p] - gap:\n",
    "          if abs(Speaks_b[S_minus[it2-os2]] - Speaks_b[last_p]) < 9:\n",
    "            last2 = it2 - os2\n",
    "            last_p = S_minus[last2]\n",
    "            c_contour = np.append(c_contour, last_p)\n",
    "            c_delete2 = np.append(c_delete2, last2)\n",
    "            gap = 1\n",
    "          os2 += 1\n",
    "        else: gap += 1\n",
    "\n",
    "    c_contour = np.flip(c_contour)\n",
    "    contour_ids = np.append(contour_ids, slice(contours.size, contours.size + c_contour.size))\n",
    "    contours = np.append(contours, c_contour)\n",
    "\n",
    "    S_plus = np.delete(S_plus, c_delete)\n",
    "    S_minus = np.delete(S_minus, c_delete2)\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  for c in contour_ids:\n",
    "    ax1.plot(Speaks_t[contours[c]], Speaks_b[contours[c]], '.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  ## **Step 4.** Melody Selection\n",
    "  # Calculate certain attributes for each contour\n",
    "\n",
    "  p_mean = np.array([np.mean(Speaks_b[contours[c]]) for c in contour_ids])\n",
    "  p_std = np.array([np.std(Speaks_b[contours[c]]) for c in contour_ids])\n",
    "  s_mean = np.array([np.mean(peak_Sb[contours[c]]) for c in contour_ids])\n",
    "  s_total = np.array([np.sum(peak_Sb[contours[c]]) for c in contour_ids])\n",
    "  s_std = np.array([np.std(peak_Sb[contours[c]]) for c in contour_ids])\n",
    "  # 4.1. Voicing Detection\n",
    "\n",
    "  # Give contours with considerable pitch deviation \"immunity\"\n",
    "  # for the rest of this step\n",
    "  not_vib = p_std < 4\n",
    "\n",
    "  # Filter contours with low salience\n",
    "  s_meanmean = np.mean(s_mean)\n",
    "  s_meanstd = np.std(s_mean)\n",
    "  v = 0.4\n",
    "  mask = not_vib & (s_mean < (s_meanmean - v*s_meanstd))\n",
    "  dell = np.flip(np.where(mask)).flatten()\n",
    "  contour_ids = np.delete(contour_ids, dell)\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  for c in contour_ids:\n",
    "    ax1.plot(Speaks_t[contours[c]], Speaks_b[contours[c]], '.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # 4.2. Octave Errors and Pitch Outliers\n",
    "  # Function definitions\n",
    "\n",
    "  # Derive melody pitch mean from given contours\n",
    "  def CreatePt(cont):\n",
    "    Pt = np.zeros(Sb.shape[1])\n",
    "    Pt_d = np.zeros(Sb.shape[1])\n",
    "\n",
    "    for c in cont:\n",
    "      k = Speaks_t[contours[c]]\n",
    "      Pt[k] += Speaks_b[contours[c]]*peak_Sb[contours[c]]\n",
    "      Pt_d[k] += peak_Sb[contours[c]]\n",
    "    mask = Pt_d != 0\n",
    "    Pt[mask] /= Pt_d[mask]\n",
    "\n",
    "    Pt_ = np.zeros(Pt.size)\n",
    "    for i in range(Pt_.size):\n",
    "      rge = slice(max([0, i-860]), min([Pt.size, i+861]))\n",
    "      Pt_[i] = np.sum(Pt[rge])\n",
    "      n = np.count_nonzero(Pt[rge])\n",
    "      if n != 0: Pt_[i] /= n\n",
    "\n",
    "    return Pt_\n",
    "\n",
    "  # Find contour overlap sections\n",
    "  def Overlaps(cont):\n",
    "    overlaps = np.zeros((0,4), dtype=int)\n",
    "    timer = np.zeros(0, dtype=int)\n",
    "    timer_ids = np.zeros((Sb.shape[1], 2), dtype=int)\n",
    "\n",
    "    for i in range(cont.size):\n",
    "      c = cont[i]\n",
    "      for j in range(Speaks_t[contours[c][0]], Speaks_t[contours[c][-1]]+1):\n",
    "        for a in range(timer_ids[j,0], timer_ids[j,1]):\n",
    "          i2 = timer[a]\n",
    "          c2 = cont[i2]\n",
    "          done = (overlaps.T[0] == i) & (overlaps.T[1] == i2)\n",
    "          if done.any(): continue\n",
    "\n",
    "          last = min([Speaks_t[contours[c][-1]], Speaks_t[contours[c2][-1]]])\n",
    "          overlaps = np.append(overlaps, [[i, i2, j, last]], axis=0)\n",
    "\n",
    "          new_x = overlaps.shape[0] - 1\n",
    "          for k in range(overlaps.shape[0]-1):\n",
    "            if (overlaps[k,0] == i or overlaps[k,1] == i or\n",
    "                overlaps[k,0] == i2 or overlaps[k,1] == i2):\n",
    "              if ((overlaps[k,3] - overlaps[k,2]) <\n",
    "                  (overlaps[new_x,3] - overlaps[new_x,2])) and k > new_x:\n",
    "                overlaps[k], overlaps[new_x] = overlaps[new_x], overlaps[k]\n",
    "                new_x = k\n",
    "        timer = np.insert(timer, timer_ids[j,1], i)\n",
    "        timer_ids.T[1, j:] += 1\n",
    "        timer_ids.T[0, (j+1):] += 1\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "  # Detect pairs of octave duplicates and pick closest to Pt\n",
    "  def PickOctave(over, Pt):\n",
    "    cont0 = contours[contour_ids[over[0]]]\n",
    "    cont1 = contours[contour_ids[over[1]]]\n",
    "    dif = np.zeros(0)\n",
    "    pt0 = np.zeros(0)\n",
    "    pt1 = np.zeros(0)\n",
    "    i0 = 0\n",
    "    i1 = 0\n",
    "\n",
    "    while Speaks_t[cont0[i0]] != over[2]:\n",
    "      if (i0+1) >= (cont0.size): break\n",
    "      else: i0 += 1\n",
    "    while Speaks_t[cont1[i1]] != over[2]:\n",
    "      if (i1+1) >= (cont1.size): break\n",
    "      else: i1 += 1\n",
    "    for t in range(over[2], over[3]+1):\n",
    "      while Speaks_t[cont0[i0]] < t:\n",
    "        if (i0+1) >= (cont0.size): break\n",
    "        else: i0 += 1\n",
    "      if Speaks_t[cont0[i0]] > t: continue\n",
    "      while Speaks_t[cont1[i1]] < t:\n",
    "        if (i1+1) >= (cont1.size): break\n",
    "        else: i1 += 1\n",
    "      if Speaks_t[cont1[i1]] > t: continue\n",
    "\n",
    "      b0 = Speaks_b[cont0[i0]]\n",
    "      b1 = Speaks_b[cont1[i1]]\n",
    "      dif = np.append(dif, abs(b0 - b1))\n",
    "      pt0 = np.append(pt0, abs(Pt[t] - b0))\n",
    "      pt1 = np.append(pt1, abs(Pt[t] - b1))\n",
    "\n",
    "    if np.mean(dif) >= 115 and np.mean(dif) <= 125:\n",
    "      if np.mean(pt0) == np.mean(pt1): return 0\n",
    "      elif np.mean(pt0) < np.mean(pt1): return 1\n",
    "      else: return 2\n",
    "    else: return 0\n",
    "  # Filter out octave duplicates and pitch outliers\n",
    "  # Repeat process three times with updated melody pitch means\n",
    "\n",
    "  Pt = CreatePt(contour_ids)\n",
    "  overlaps = Overlaps(contour_ids)\n",
    "\n",
    "  for _ in range(3):\n",
    "    rest = range(contour_ids.size)\n",
    "\n",
    "    dell = np.zeros(0, dtype=int)\n",
    "    # probably remove for\n",
    "    for i in range(overlaps.shape[0]):\n",
    "      if ((dell == overlaps[i,0]) | (dell == overlaps[i,1])).any(): continue\n",
    "      result = PickOctave(overlaps[i], Pt)\n",
    "      if result == 1: octave = overlaps[i,1]\n",
    "      elif result == 2: octave = overlaps[i,0]\n",
    "      if result != 0:\n",
    "        dell = np.append(dell, octave)\n",
    "    rest = np.delete(rest, dell)\n",
    "    Pt = CreatePt(contour_ids[rest])\n",
    "\n",
    "    dell = np.zeros(0, dtype=int)\n",
    "    for i in range(rest.size):\n",
    "      cont = contours[contour_ids[rest[i]]]\n",
    "      ptdif = np.zeros(0)\n",
    "      t = Speaks_t[cont]\n",
    "      ptdif = np.append(ptdif, abs(Speaks_b[cont] - Pt[t]))\n",
    "      if np.mean(ptdif) > 120:\n",
    "        dell = np.append(dell, i)\n",
    "    rest = np.delete(rest, dell)\n",
    "    Pt = CreatePt(contour_ids[rest])\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  for c in contour_ids[rest]:\n",
    "    ax1.plot(Speaks_t[contours[c]], Speaks_b[contours[c]], 'k.')\n",
    "  ax1.plot(np.arange(Pt.size), Pt, 'r--')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  # 4.3. Final Melody Selection\n",
    "\n",
    "  contour_ids = contour_ids[rest]\n",
    "  s_total2 = s_total[rest]\n",
    "\n",
    "  overlaps = Overlaps(contour_ids)\n",
    "  not_final = np.where(s_total2[overlaps.T[0]] < s_total2[overlaps.T[1]],\n",
    "                       overlaps.T[0], overlaps.T[1])\n",
    "\n",
    "  final = np.delete(range(contour_ids.size), not_final)\n",
    "  final_contours = contour_ids[final]\n",
    "  # Graph only for illustration purposes\n",
    "  fig1, ax1 = plt.subplots(figsize=(9., 6.))\n",
    "\n",
    "  im1 = ax1.imshow(Sb, origin='lower', aspect='auto',\n",
    "                   extent=new_extents, cmap='viridis')\n",
    "  for c in final_contours:\n",
    "    ax1.plot(Speaks_t[contours[c]] * x_scale, Speaks_b[contours[c]], 'y.')\n",
    "\n",
    "  fig1.colorbar(im1)\n",
    "  fig1.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "  for i in range(final_contours.size):\n",
    "    for j in range(i+1, final_contours.size):\n",
    "      if final_contours[i].start > final_contours[j].start:\n",
    "        final_contours[i], final_contours[j] = final_contours[j], final_contours[i]\n",
    "\n",
    "  final_t = np.zeros(0, dtype=int)\n",
    "  final_b = np.zeros(0, dtype=int)\n",
    "  for f in final_contours:\n",
    "    final_t = np.append(final_t, Speaks_t[contours[f]])\n",
    "    final_b = np.append(final_b, Speaks_b[contours[f]])\n",
    "\n",
    "  if (filename is not None):\n",
    "    with open(filename, \"w\") as txt:\n",
    "      txt.write(\"Time,Pitch\\n\")\n",
    "      for i in range(final_t.size):\n",
    "        txt.write(str(final_t[i]) + \",\" + str(final_b[i]) + \"\\n\")\n",
    "  return [final_t, final_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://replaygain.hydrogenaud.io/equal_loudness.html \\\\\n",
    "[2] https://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamongomezmelodytaslp2012.pdf \\\\\n",
    "[3] https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf \\\\\n",
    "[4] https://dafx.de/paper-archive/2006/papers/p_247.pdf \\\\\n",
    "[5] https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00038847/ilm1-2017000136.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
