{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPaoKYMxbpBu"
   },
   "source": [
    "# **MAAS (GPU) Filter Module**\n",
    "\n",
    "This notebook details the process of filtering wav audio files for usage in the MAAS project. The first four steps are an implementation of the process described by Salamon and GÃ³mez [2]. The rest is inspired by the research done by Wang [3].\n",
    "\n",
    "DISCLAIMER: English was purposely used to write comments and cells as it suits our ideas better.\n",
    "\n",
    "NOTE: This notebook is a module strictly required by MAAS_UI.ipynb to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjzqalmaMyZ2"
   },
   "outputs": [],
   "source": [
    "# Define Mauricio's Audio Analysis System function\n",
    "def MAAS_filter(data, sr = 44100, filename = None):\n",
    "  ## **Step 1.** Sinusoid Extraction\n",
    "  # 1.1. Equal Loudness Filtering\n",
    "  # Filter approximation by [1]\n",
    "\n",
    "  yule_b = cp.array([0.05418656406430, -0.02911007808948, -0.00848709379851, -0.00851165645469,\n",
    "                     -0.00834990904936, 0.02245293253339, -0.02596338512915, 0.01624864962975,\n",
    "                     -0.00240879051584, 0.00674613682247, -0.00187763777362])\n",
    "  yule_a = cp.array([1.0, -3.47845948550071, 6.36317777566148, -8.54751527471874, 9.47693607801280,\n",
    "                     -8.81498681370155, 6.85401540936998, -4.39470996079559, 2.19611684890774,\n",
    "                     -0.75104302451432, 0.13149317958808])\n",
    "  butter_b = cp.array([0.98500175787242, -1.97000351574484, 0.98500175787242])\n",
    "  butter_a = cp.array([1.0, -1.96977855582618, 0.97022847566350])\n",
    "\n",
    "  num = cp.convolve(yule_b, butter_b)\n",
    "  den = cp.convolve(yule_a, butter_a)\n",
    "\n",
    "  eq_data = sig.lfilter(num, den, data)\n",
    "  # 1.2. Spectral Transform\n",
    "  # Apply Short-Time Fourier Transform\n",
    "\n",
    "  # Constants as calculated by [2]\n",
    "  # Values specific to 44.1 kHz, should be scalable to other sample rates\n",
    "  M = 2048\n",
    "  N = 8192\n",
    "  H = 128\n",
    "\n",
    "  win = sig.windows.hann(M, False)\n",
    "  f, t, Sx = sig.stft(eq_data, fs=sr, window=win, nperseg=M, noverlap=H, nfft=N, return_onesided=False)\n",
    "    \n",
    "  # 1.3. Frequency/Amplitude Correction\n",
    "  # Identify local maxima of each time frame\n",
    "\n",
    "  peaks = sig.argrelmax(abs(Sx), axis=0, order=2)\n",
    "  pcp = max(abs(Sx[peaks[0], peaks[1]])) / 20\n",
    "  peak_ids = abs(Sx[peaks[0], peaks[1]]) > pcp\n",
    "  peaks_f = peaks[0][peak_ids]\n",
    "  peaks_t = peaks[1][peak_ids]\n",
    "\n",
    "  # x and y scale actually important. do not delete\n",
    "  x_scale = data.size/Sx.shape[1]\n",
    "  y_scale = sr/N\n",
    "    \n",
    "  # Correct frequency and amplitude based on peaks' phase\n",
    "  # Done by computing instantaneous frequency (IF) and magnitude (Ai)\n",
    "  # Further clarification about this implementation by [4] and [5]\n",
    "\n",
    "  y_scale = sr/N\n",
    "  k_offset = cp.angle(Sx[peaks_f, peaks_t]) - (2*cp.pi*H*peaks_f/N)\n",
    "  mask = peaks_t > 0\n",
    "  k_offset[mask] -= cp.angle(Sx[peaks_f[mask], peaks_t[mask]-1])\n",
    "  k_offset = k_offset%(2*cp.pi)\n",
    "  mask = k_offset > cp.pi\n",
    "  k_offset[mask] -= 2*cp.pi\n",
    "  Wh = cp.sinc(k_offset) / (2*(1 - k_offset**2))\n",
    "  k_offset *= N/(2*cp.pi*H)\n",
    "\n",
    "  IF = (peaks_f + k_offset) * y_scale\n",
    "  Ai = abs(Sx[peaks_f, peaks_t]) / (2*Wh)\n",
    "    \n",
    "  ## **Step 2.** Salience Function Computation\n",
    "  # Constant values given by [2]\n",
    "  alpha = 0.8\n",
    "  beta = 1\n",
    "  gamma = 2\n",
    "  Nh = 20\n",
    "\n",
    "  # Useful peak indexing per frame\n",
    "  peaks_by_t = cp.stack((peaks_t, cp.arange(peaks_t.size)), axis=1)\n",
    "  peaks_by_t = peaks_by_t[cp.argsort(peaks_by_t[:,0])]\n",
    "\n",
    "  # Calculate number of peaks and highest peak per frame\n",
    "  peaks_per_f = cp.zeros(Sx.shape[1], dtype=int)\n",
    "  max_peak = cp.zeros(peaks_per_f.size, dtype=int)\n",
    "\n",
    "  for i in range(peaks_t.size):\n",
    "    peaks_per_f[peaks_t[i]] += 1\n",
    "    if IF[i] > max_peak[peaks_t[i]]:\n",
    "      max_peak[peaks_t[i]] = i\n",
    "  # Function definitions\n",
    "\n",
    "  # Bin: Computes (discrete) bin number of given frequency\n",
    "  def Bin(fi):\n",
    "    return cp.floor(120*cp.log2(fi/55) + 1)\n",
    "\n",
    "  # Threshold: Whether or not a given peak is loud enough\n",
    "  # compared to highest peak in its frame\n",
    "  def Threshold(a, t, g):\n",
    "    tr = cp.log10(abs(Ai[max_peak[t]] / a))\n",
    "    ea = cp.where(tr < g, 1, 0)\n",
    "    return ea\n",
    "\n",
    "  # Weight: Assigns (cos^2) weight to bin if the given peak is a\n",
    "  # multiple of the bin's center frequency (harmonic)\n",
    "  def Weight(a, b, h, fi):\n",
    "    nh = cp.arange(h)+1\n",
    "    d = abs(Bin(cp.outer(fi, (1 / nh))) - b)/10\n",
    "    w = (a**(nh-1)) * cp.cos(cp.pi*d/2)**2\n",
    "    w[(d > 1)] = 0\n",
    "    return cp.sum(w, axis=1)\n",
    "  # Computation of every bin's salience per frame\n",
    "\n",
    "  Sb = cp.zeros((600, Sx.shape[1]))\n",
    "\n",
    "  index = 0\n",
    "  for l in range(Sb.shape[1]):\n",
    "    idx = slice(index, index + peaks_per_f[l])\n",
    "    ea = Threshold(Ai[peaks_by_t[idx,1]], l, gamma)\n",
    "    ab = abs(Ai[peaks_by_t[idx,1]])**beta\n",
    "    for b in range(Sb.shape[0]):\n",
    "      w = Weight(alpha, b+1, Nh, IF[peaks_by_t[idx,1]])\n",
    "      Sb[b, l] = cp.sum(w * ab)\n",
    "    index += peaks_per_f[l]\n",
    "      \n",
    "  # Identify local maxima of each time frame\n",
    "\n",
    "  Speaks = sig.argrelmax(Sb, axis=0, order=5)\n",
    "  Speaks_arr = cp.array([Speaks[0], Speaks[1]]).T\n",
    "  Speaks_arr = Speaks_arr[cp.argsort(Speaks_arr[:,1])]\n",
    "\n",
    "  pcp2 = max(abs(Sb[Speaks_arr[:,0], Speaks_arr[:,1]])) / 10\n",
    "  Speak_ids = abs(Sb[Speaks_arr[:,0], Speaks_arr[:,1]]) > pcp2\n",
    "  Speaks_b = Speaks_arr[Speak_ids, 0].flatten()\n",
    "  Speaks_t = Speaks_arr[Speak_ids, 1].flatten()\n",
    "    \n",
    "  ## **Step 3.** Peak Streaming\n",
    "  # Calculate highest salience peaks per frame\n",
    "  # and filter low salience peaks\n",
    "\n",
    "  peak_Sb = Sb[Speaks_b, Speaks_t]\n",
    "  max_Speak = cp.zeros(Sb.shape[1], dtype=int)\n",
    "\n",
    "  for i in range(peak_Sb.size):\n",
    "    if peak_Sb[i] > peak_Sb[max_Speak[Speaks_t[i]]]:\n",
    "      max_Speak[Speaks_t[i]] = i\n",
    "\n",
    "  max_id = max_Speak[Speaks_t]\n",
    "  mask = peak_Sb < peak_Sb[max_id] * 0.9\n",
    "  S_minus = cp.arange(peak_Sb.size)[mask]\n",
    "  # Filter remaining peaks based on general frame salience\n",
    "\n",
    "  boolarr = cp.ones(peak_Sb.size, dtype=bool)\n",
    "  boolarr[S_minus] = False\n",
    "\n",
    "  N = peak_Sb.size - S_minus.size\n",
    "  s_mean = cp.average(peak_Sb[boolarr])\n",
    "  s_dev = cp.std(peak_Sb[boolarr])\n",
    "  min_S = s_mean - 0.9*s_dev\n",
    "\n",
    "  mask = (boolarr == 1) & (peak_Sb < min_S)\n",
    "  S_minus = cp.append(S_minus, cp.arange(peak_Sb.size)[mask])\n",
    "  boolarr[mask] = 0\n",
    "    \n",
    "  # Actual contour creation\n",
    "  # Travel through the remaining ordered peaks and group them based on\n",
    "  # time and pitch continuity\n",
    "  # Might use some filtered peaks to maintain the continuities\n",
    "\n",
    "  S_plus = cp.array(cp.where(boolarr == 1)).flatten()\n",
    "  contours = cp.zeros(S_plus.size, dtype=int)\n",
    "  contour_ids = cp.zeros((0,2), dtype=int)\n",
    "  first_f = min(Speaks_t)\n",
    "  last_f = max(Speaks_t)\n",
    "  contours_idx = 0\n",
    "\n",
    "  while S_plus.size:\n",
    "    wpeak_Sb = cp.copy(peak_Sb[S_plus])\n",
    "    it = cp.argmax(wpeak_Sb)\n",
    "    it2 = 0\n",
    "    mask = Speaks_t[S_minus] == Speaks_t[it]\n",
    "    if mask.any(): it2 = cp.arange(S_minus.size)[mask][0]\n",
    "\n",
    "    c_contour = cp.zeros(1, dtype=int)\n",
    "    c_delete = cp.zeros(1, dtype=int)\n",
    "    c_delete2 = cp.zeros(1, dtype=int)\n",
    "    c_contour[0] = S_plus[it]\n",
    "    c_delete[0] = it\n",
    "\n",
    "    # Forward\n",
    "    last_p = S_plus[it]\n",
    "    last = it\n",
    "    os = 1\n",
    "    last2 = it2\n",
    "    os2 = 1\n",
    "    gap = 1\n",
    "\n",
    "    while gap < 35 and (Speaks_t[last_p] + gap) <= last_f:\n",
    "      if (it+os) < S_plus.size and Speaks_t[S_plus[it+os]] == Speaks_t[last_p]:\n",
    "        os += 1\n",
    "      elif (it+os) < S_plus.size and Speaks_t[S_plus[it+os]] == Speaks_t[last_p] + gap:\n",
    "        if abs(Speaks_b[S_plus[it+os]] - Speaks_b[last_p]) < 9:\n",
    "          last = it + os\n",
    "          last_p = S_plus[last]\n",
    "          c_contour = cp.append(c_contour, last_p)\n",
    "          c_delete = cp.append(c_delete, last)\n",
    "          gap = 1\n",
    "        os += 1\n",
    "      else:\n",
    "        if (it2+os2) < S_minus.size and Speaks_t[S_minus[it2+os2]] == Speaks_t[last_p]:\n",
    "          os2 += 1\n",
    "        elif (it2+os2) < S_minus.size and Speaks_t[S_minus[it2+os2]] == Speaks_t[last_p] + gap:\n",
    "          if abs(Speaks_b[S_minus[it2+os2]] - Speaks_b[last_p]) < 9:\n",
    "            last2 = it2 + os2\n",
    "            last_p = S_minus[last2]\n",
    "            c_contour = cp.append(c_contour, last_p)\n",
    "            c_delete2 = cp.append(c_delete2, last2)\n",
    "            gap = 1\n",
    "          os2 += 1\n",
    "        else: gap += 1\n",
    "\n",
    "    # Backward\n",
    "    c_contour = cp.flip(c_contour)\n",
    "    last_p = S_plus[it]\n",
    "    last = it\n",
    "    os = 1\n",
    "    last2 = it2\n",
    "    os2 = 1\n",
    "    gap = 1\n",
    "\n",
    "    while gap < 35 and (Speaks_t[last_p] - gap) >= first_f:\n",
    "      if (it-os) >= 0 and Speaks_t[S_plus[it-os]] == Speaks_t[last_p]:\n",
    "        os += 1\n",
    "      elif (it-os) >= 0 and Speaks_t[S_plus[it-os]] == Speaks_t[last_p] - gap:\n",
    "        if abs(Speaks_b[S_plus[it-os]] - Speaks_b[last_p]) < 9:\n",
    "          last = it - os\n",
    "          last_p = S_plus[last]\n",
    "          c_contour = cp.append(c_contour, last_p)\n",
    "          c_delete = cp.append(c_delete, last)\n",
    "          gap = 1\n",
    "        os += 1\n",
    "      else:\n",
    "        if (it2-os2) >= 0 and Speaks_t[S_minus[it2-os2]] == Speaks_t[last_p]:\n",
    "          os2 += 1\n",
    "        elif (it2-os2) >= 0 and Speaks_t[S_minus[it2-os2]] == Speaks_t[last_p] - gap:\n",
    "          if abs(Speaks_b[S_minus[it2-os2]] - Speaks_b[last_p]) < 9:\n",
    "            last2 = it2 - os2\n",
    "            last_p = S_minus[last2]\n",
    "            c_contour = cp.append(c_contour, last_p)\n",
    "            c_delete2 = cp.append(c_delete2, last2)\n",
    "            gap = 1\n",
    "          os2 += 1\n",
    "        else: gap += 1\n",
    "\n",
    "    c_contour = cp.flip(c_contour)\n",
    "    contour_ids = cp.append(contour_ids, [[contours.size, contours.size + c_contour.size]], axis=0)\n",
    "    contours[contours_idx] = c_contour\n",
    "\n",
    "    S_plus = cp.delete(S_plus, c_delete)\n",
    "    S_minus = cp.delete(S_minus, c_delete2)\n",
    "    contours_idx += 1\n",
    "      \n",
    "  ## **Step 4.** Melody Selection\n",
    "  # Calculate certain attributes for each contour\n",
    "\n",
    "  p_mean = cp.array([cp.mean(Speaks_b[contours[c[0]:c[1]]]) for c in contour_ids])\n",
    "  p_std = cp.array([cp.std(Speaks_b[contours[c[0]:c[1]]]) for c in contour_ids])\n",
    "  s_mean = cp.array([cp.mean(peak_Sb[contours[c[0]:c[1]]]) for c in contour_ids])\n",
    "  s_total = cp.array([cp.sum(peak_Sb[contours[c[0]:c[1]]]) for c in contour_ids])\n",
    "  s_std = cp.array([cp.std(peak_Sb[contours[c[0]:c[1]]]) for c in contour_ids])\n",
    "  # 4.1. Voicing Detection\n",
    "\n",
    "  # Give contours with considerable pitch deviation \"immunity\"\n",
    "  # for the rest of this step\n",
    "  not_vib = p_std < 4\n",
    "\n",
    "  # Filter contours with low salience\n",
    "  s_meanmean = cp.mean(s_mean)\n",
    "  s_meanstd = cp.std(s_mean)\n",
    "  v = 0.4\n",
    "  mask = not_vib & (s_mean < (s_meanmean - v*s_meanstd))\n",
    "  dell = cp.flip(cp.where(mask)[0]).flatten()\n",
    "  contour_ids = cp.delete(contour_ids, dell)\n",
    "      \n",
    "  # 4.2. Octave Errors and Pitch Outliers\n",
    "  # Function definitions\n",
    "\n",
    "  # Derive melody pitch mean from given contours\n",
    "  def CreatePt(cont):\n",
    "    Pt = cp.zeros(Sb.shape[1])\n",
    "    Pt_d = cp.zeros(Sb.shape[1])\n",
    "\n",
    "    for c in cont:\n",
    "      k = Speaks_t[contours[c]]\n",
    "      Pt[k] += Speaks_b[contours[c]]*peak_Sb[contours[c]]\n",
    "      Pt_d[k] += peak_Sb[contours[c]]\n",
    "    mask = Pt_d != 0\n",
    "    Pt[mask] /= Pt_d[mask]\n",
    "\n",
    "    Pt_ = cp.zeros(Pt.size)\n",
    "    for i in range(Pt_.size):\n",
    "      rge = slice(max([0, i-860]), min([Pt.size, i+861]))\n",
    "      Pt_[i] = cp.sum(Pt[rge])\n",
    "      n = cp.count_nonzero(Pt[rge])\n",
    "      if n != 0: Pt_[i] /= n\n",
    "\n",
    "    return Pt_\n",
    "\n",
    "  # Find contour overlap sections\n",
    "  def Overlaps(cont):\n",
    "    overlaps = cp.zeros((0,4), dtype=int)\n",
    "    timer = cp.zeros(0, dtype=int)\n",
    "    timer_ids = cp.zeros((Sb.shape[1], 2), dtype=int)\n",
    "\n",
    "    for i in range(cont.size):\n",
    "      c = cont[i]\n",
    "      for j in range(Speaks_t[contours[c][0]], Speaks_t[contours[c][-1]]+1):\n",
    "        for a in range(timer_ids[j,0], timer_ids[j,1]):\n",
    "          i2 = timer[a]\n",
    "          c2 = cont[i2]\n",
    "          done = (overlaps.T[0] == i) & (overlaps.T[1] == i2)\n",
    "          if done.any(): continue\n",
    "\n",
    "          last = min([Speaks_t[contours[c][-1]], Speaks_t[contours[c2][-1]]])\n",
    "          overlaps = cp.append(overlaps, [[i, i2, j, last]], axis=0)\n",
    "\n",
    "          new_x = overlaps.shape[0] - 1\n",
    "          for k in range(overlaps.shape[0]-1):\n",
    "            if (overlaps[k,0] == i or overlaps[k,1] == i or\n",
    "                overlaps[k,0] == i2 or overlaps[k,1] == i2):\n",
    "              if ((overlaps[k,3] - overlaps[k,2]) <\n",
    "                  (overlaps[new_x,3] - overlaps[new_x,2])) and k > new_x:\n",
    "                overlaps[k], overlaps[new_x] = overlaps[new_x], overlaps[k]\n",
    "                new_x = k\n",
    "        timer = cp.insert(timer, timer_ids[j,1], i)\n",
    "        timer_ids.T[1, j:] += 1\n",
    "        timer_ids.T[0, (j+1):] += 1\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "  # Detect pairs of octave duplicates and pick closest to Pt\n",
    "  def PickOctave(over, Pt):\n",
    "    cont0 = contours[contour_ids[over[0]][0]:contour_ids[over[0]][1]]\n",
    "    cont1 = contours[contour_ids[over[1]][0]:contour_ids[over[1]][1]]\n",
    "    dif = cp.zeros(0)\n",
    "    pt0 = cp.zeros(0)\n",
    "    pt1 = cp.zeros(0)\n",
    "    i0 = 0\n",
    "    i1 = 0\n",
    "\n",
    "    while Speaks_t[cont0[i0]] != over[2]:\n",
    "      if (i0+1) >= (cont0.size): break\n",
    "      else: i0 += 1\n",
    "    while Speaks_t[cont1[i1]] != over[2]:\n",
    "      if (i1+1) >= (cont1.size): break\n",
    "      else: i1 += 1\n",
    "    for t in range(over[2], over[3]+1):\n",
    "      while Speaks_t[cont0[i0]] < t:\n",
    "        if (i0+1) >= (cont0.size): break\n",
    "        else: i0 += 1\n",
    "      if Speaks_t[cont0[i0]] > t: continue\n",
    "      while Speaks_t[cont1[i1]] < t:\n",
    "        if (i1+1) >= (cont1.size): break\n",
    "        else: i1 += 1\n",
    "      if Speaks_t[cont1[i1]] > t: continue\n",
    "\n",
    "      b0 = Speaks_b[cont0[i0]]\n",
    "      b1 = Speaks_b[cont1[i1]]\n",
    "      dif = cp.append(dif, abs(b0 - b1))\n",
    "      pt0 = cp.append(pt0, abs(Pt[t] - b0))\n",
    "      pt1 = cp.append(pt1, abs(Pt[t] - b1))\n",
    "\n",
    "    if cp.mean(dif) >= 115 and cp.mean(dif) <= 125:\n",
    "      if cp.mean(pt0) == cp.mean(pt1): return 0\n",
    "      elif cp.mean(pt0) < cp.mean(pt1): return 1\n",
    "      else: return 2\n",
    "    else: return 0\n",
    "  # Filter out octave duplicates and pitch outliers\n",
    "  # Repeat process three times with updated melody pitch means\n",
    "\n",
    "  Pt = CreatePt(contour_ids)\n",
    "  overlaps = Overlaps(contour_ids)\n",
    "\n",
    "  for _ in range(3):\n",
    "    rest = range(contour_ids.size)\n",
    "\n",
    "    dell = cp.zeros(0, dtype=int)\n",
    "    # probably remove for\n",
    "    for i in range(overlaps.shape[0]):\n",
    "      if ((dell == overlaps[i,0]) | (dell == overlaps[i,1])).any(): continue\n",
    "      result = PickOctave(overlaps[i], Pt)\n",
    "      if result == 1: octave = overlaps[i,1]\n",
    "      elif result == 2: octave = overlaps[i,0]\n",
    "      if result != 0:\n",
    "        dell = cp.append(dell, octave)\n",
    "    rest = cp.delete(rest, dell)\n",
    "    Pt = CreatePt(contour_ids[rest])\n",
    "\n",
    "    dell = cp.zeros(0, dtype=int)\n",
    "    for i in range(rest.size):\n",
    "      cont = contours[contour_ids[rest[i]][0]:contour_ids[rest[i]][1]]\n",
    "      ptdif = cp.zeros(0)\n",
    "      t = Speaks_t[cont]\n",
    "      ptdif = cp.append(ptdif, abs(Speaks_b[cont] - Pt[t]))\n",
    "      if cp.mean(ptdif) > 120:\n",
    "        dell = cp.append(dell, i)\n",
    "    rest = cp.delete(rest, dell)\n",
    "    Pt = CreatePt(contour_ids[rest])\n",
    "      \n",
    "  # 4.3. Final Melody Selection\n",
    "\n",
    "  contour_ids = contour_ids[rest]\n",
    "  s_total2 = s_total[rest]\n",
    "\n",
    "  overlaps = Overlaps(contour_ids)\n",
    "  not_final = cp.where(s_total2[overlaps.T[0]] < s_total2[overlaps.T[1]],\n",
    "                       overlaps.T[0], overlaps.T[1])\n",
    "\n",
    "  final = cp.delete(range(contour_ids.size), not_final)\n",
    "  final_contours = contour_ids[final]\n",
    "    \n",
    "  ## **Step 5.** Interval Timestamping\n",
    "  # Sort contours by time\n",
    "\n",
    "  fstart = cp.zeros(final_contours.size, dtype=int)\n",
    "  for i in range(fstart.size):\n",
    "    fstart[i] = Speaks_t[contours[final_contours[i][0]]]\n",
    "  f0 = cp.stack((final_contours, fstart), axis=1)\n",
    "  f0 = f0[cp.argsort(f0[:,1])]\n",
    "\n",
    "  final_peaks = cp.zeros(0, dtype=int)\n",
    "  fp_ids = cp.zeros((fstart.size,2), dtype=int)\n",
    "  for i in range(fstart.size):\n",
    "    len = contours[f0[i,0]].size\n",
    "    fp_ids[i] = [final_peaks.size, final_peaks.size + len]\n",
    "    final_peaks = cp.append(final_peaks, contours[f0[i,0]])\n",
    "  # Use contour with lowest pitch standard deviation\n",
    "  # as a basis for pitch quantization\n",
    "  # (Poor man's autotune)\n",
    "\n",
    "  final_t = Speaks_t[final_peaks]\n",
    "  final_b = Speaks_b[final_peaks]\n",
    "\n",
    "  p_std = cp.array([cp.std(final_b[fp[0]:fp[1]]) for fp in fp_ids])\n",
    "  p_base_id = fp_ids[cp.argmin(p_std)]\n",
    "  p_base = round(cp.mean(final_b[p_base_id[0]:p_base_id[1]]))\n",
    "\n",
    "  qnt = 5   # Basically quantize by quarter tones\n",
    "  final_b -= p_base % qnt\n",
    "  final_b = qnt*cp.floor((final_b/qnt) + 0.5) + (p_base % qnt)\n",
    "    \n",
    "  def Timestamp(a, b):\n",
    "    duration = final_t[b] - final_t[a]\n",
    "    time = final_t[a] + (duration / 2)\n",
    "    interval = final_b[b] - final_b[a]\n",
    "    return time, interval, duration\n",
    "  notes = cp.zeros((1, 2), dtype=int)\n",
    "  it = 0\n",
    "  this_p = 0\n",
    "  while it < final_peaks.size:\n",
    "    if final_b[it] != this_p:\n",
    "      notes[-1, 1] = it - 1\n",
    "      notes = cp.append(notes, [[it, 0]], axis=0)\n",
    "    this_p = final_b[it]\n",
    "    it += 1\n",
    "  notes[-1, 1] = final_peaks.size - 1\n",
    "  notes = notes[1:]\n",
    "\n",
    "  Time_array = cp.zeros(0)\n",
    "  Interval_array = cp.zeros(0)\n",
    "  for i in range(notes.shape[0] - 1):\n",
    "    j = 1\n",
    "    note1 = notes[i, 1]\n",
    "    note2 = notes[i+j, 0]\n",
    "    this_time, this_inter, base_dr = Timestamp(note1, note2)\n",
    "\n",
    "    dr_offset = 0\n",
    "    while dr_offset <= 50:\n",
    "      Time_array = cp.append(Time_array, this_time)\n",
    "      Interval_array = cp.append(Interval_array, this_inter)\n",
    "      j += 1\n",
    "      if i+j >= notes.shape[0]: break\n",
    "\n",
    "      note2 = notes[i+j, 0]\n",
    "      this_time, this_inter, dr_offset = Timestamp(note1, note2)\n",
    "      dr_offset -= base_dr\n",
    "        \n",
    "  if (filename is not None):\n",
    "    with open(filename, \"w\") as txt:\n",
    "      txt.write(\"Time,Interval\\n\")\n",
    "      for i in range(Time_array.size):\n",
    "        txt.write(str(Time_array[i]) + \",\" + str(Interval_array[i]) + \"\\n\")\n",
    "  return [Time_array, Interval_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0Im9iYA65Io"
   },
   "source": [
    "## References\n",
    "\n",
    "[1] https://replaygain.hydrogenaud.io/equal_loudness.html \\\\\n",
    "[2] https://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamongomezmelodytaslp2012.pdf \\\\\n",
    "[3] https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf \\\\\n",
    "[4] https://dafx.de/paper-archive/2006/papers/p_247.pdf \\\\\n",
    "[5] https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00038847/ilm1-2017000136.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
